// cspell:word millis

import React from "react";
import { Time, fromMillis, fromNanoSec } from "@foxglove/rostime";
import { PoseInFrame, CompressedImage } from "@foxglove/schemas";
import {
  FoxgloveMessageSchema,
  foxgloveMessageSchemas,
  foxgloveEnumSchemas,
  generateProto,
} from "@foxglove/schemas/internal";
import zstd from "@foxglove/wasm-zstd";
import { McapWriter } from "@mcap/core";
import { EventEmitter } from "eventemitter3";
import Queue from "promise-queue";
import protobufjs from "protobufjs";
import descriptor from "protobufjs/ext/descriptor";
import { useCallback, useEffect, useRef, useState } from "react";
import { create } from "zustand";

type ProtobufObject<Message> = {
  [K in keyof Message]: Message[K] extends { sec: number; nsec: number }
    ? { seconds: number | bigint; nanos: number }
    : Message[K];
};

function toProtobufTime({ sec, nsec }: Time): {
  seconds: number | bigint;
  nanos: number;
} {
  return { seconds: sec, nanos: nsec };
}

type MouseEventMessage = {
  clientX: number;
  clientY: number;
};

const MouseEventSchema = {
  type: "object",
  properties: {
    clientX: { type: "number" },
    clientY: { type: "number" },
  },
};

type ProtobufChannelInfo = {
  id: number;
  rootType: protobufjs.Type;
};
async function addProtobufChannel(
  writer: McapWriter,
  topic: string,
  rootSchema: FoxgloveMessageSchema
): Promise<ProtobufChannelInfo> {
  const schemaName = `foxglove.${rootSchema.name}`;

  const root = new protobufjs.Root();
  root.addJSON(
    protobufjs.common.get("google/protobuf/timestamp.proto")!.nested!
  );
  root.addJSON(
    protobufjs.common.get("google/protobuf/duration.proto")!.nested!
  );

  function addMessageSchema(msgSchema: FoxgloveMessageSchema) {
    const nestedEnums = Object.values(foxgloveEnumSchemas).filter(
      (enumSchema) => enumSchema.parentSchemaName === msgSchema.name
    );
    const protoSrc = generateProto(msgSchema, nestedEnums);
    const parseResult = protobufjs.parse(protoSrc, { keepCase: true });
    // parseResult.root.nestedArray[0].name = "foxglove";
    const filename = `foxglove/${msgSchema.name}.proto`;
    parseResult.root.nestedArray[0]!.filename = filename;
    root.add(parseResult.root.nestedArray[0]!);

    for (const field of msgSchema.fields) {
      if (field.type.type === "nested") {
        addMessageSchema(field.type.schema);
      }
    }
  }
  addMessageSchema(rootSchema);

  const rootType = root.lookupType(schemaName);
  const descriptorSet = root.toDescriptor("proto3");
  for (const file of descriptorSet.file) {
    // protobufjs does not generate dependency fields, so fix them up manually
    if (file.name == undefined || file.name.length === 0) {
      throw new Error(
        `Missing filename for ${file.package ?? "(unknown package)"}`
      );
    }
    if (file.name !== "google_protobuf.proto") {
      // default filename generated by toDescriptor
      file.dependency = ["google_protobuf.proto"];
    }
  }

  const schemaId = await writer.registerSchema({
    name: schemaName,
    encoding: "protobuf",
    data: descriptor.FileDescriptorSet.encode(descriptorSet).finish(),
  });
  const id = await writer.registerChannel({
    topic,
    messageEncoding: "protobuf",
    schemaId,
    metadata: new Map(),
  });

  return { rootType, id };
}

type RecorderEvents = {
  update: () => void;
  chunk: () => void;
};

class Recorder extends EventEmitter<RecorderEvents> {
  #textEncoder = new TextEncoder();
  #writer?: McapWriter;
  /** Used to ensure all operations on the McapWriter are sequential */
  #queue = new Queue(/*maxPendingPromises=*/ 1);
  #mouseChannelId?: Promise<number>;
  #mouseChannelSeq = 0;
  #poseChannel?: Promise<ProtobufChannelInfo>;
  #poseChannelSeq = 0;
  #cameraChannel?: Promise<ProtobufChannelInfo>;
  #cameraChannelSeq = 0;

  #blobParts: Uint8Array[] = [];
  bytesWritten = 0n;
  messageCount = 0;

  constructor() {
    super();
    this.#reinitializeWriter();
  }

  #reinitializeWriter() {
    const promise = this.#queue.add(async () => {
      await zstd.isLoaded;
      this.#blobParts = [];
      this.bytesWritten = 0n;
      this.messageCount = 0;
      this.#writer = new McapWriter({
        chunkSize: 5 * 1024,
        compressChunk(data) {
          return { compression: "zstd", compressedData: zstd.compress(data) };
        },
        writable: {
          position: () => this.bytesWritten,
          write: async (buffer: Uint8Array) => {
            this.#blobParts.push(buffer);
            this.bytesWritten += BigInt(buffer.byteLength);
            this.#emit();
            this.emit("chunk");
          },
        },
      });
      await this.#writer.start({
        library: "MCAP web demo",
        profile: "",
      });

      const mouseSchemaId = await this.#writer.registerSchema({
        name: "MouseEvent",
        encoding: "jsonschema",
        data: this.#textEncoder.encode(JSON.stringify(MouseEventSchema)),
      });
      const mouseChannelId = await this.#writer.registerChannel({
        topic: "mouse",
        messageEncoding: "json",
        schemaId: mouseSchemaId,
        metadata: new Map(),
      });

      const poseChannel = await addProtobufChannel(
        this.#writer,
        "pose",
        foxgloveMessageSchemas.PoseInFrame
      );
      const cameraChannel = await addProtobufChannel(
        this.#writer,
        "camera",
        foxgloveMessageSchemas.CompressedImage
      );

      this.#emit();
      return { mouseChannelId, poseChannel, cameraChannel };
    });
    this.#mouseChannelId = promise.then(({ mouseChannelId }) => mouseChannelId);
    this.#poseChannel = promise.then(({ poseChannel }) => poseChannel);
    this.#cameraChannel = promise.then(({ cameraChannel }) => cameraChannel);
  }

  #time(): bigint {
    const milliseconds = +new Date();
    return BigInt(milliseconds) * 1_000_000n;
  }

  #emit() {
    this.emit("update");
  }

  async addMouseEvent(msg: MouseEventMessage): Promise<void> {
    void this.#queue.add(async () => {
      if (!this.#writer || !this.#mouseChannelId) {
        return;
      }
      const now = this.#time();
      await this.#writer.addMessage({
        sequence: this.#mouseChannelSeq++,
        channelId: await this.#mouseChannelId,
        logTime: now,
        publishTime: now,
        data: this.#textEncoder.encode(JSON.stringify(msg)),
      });
      this.messageCount++;
      this.#emit();
    });
  }

  async addPose(msg: ProtobufObject<PoseInFrame>): Promise<void> {
    void this.#queue.add(async () => {
      if (!this.#writer || !this.#poseChannel) {
        return;
      }
      const now = this.#time();
      const { id, rootType } = await this.#poseChannel;
      await this.#writer.addMessage({
        sequence: this.#poseChannelSeq++,
        channelId: id,
        logTime: now,
        publishTime: now,
        data: rootType.encode(msg).finish(),
      });
      this.messageCount++;
      this.#emit();
    });
  }

  async addCameraImage(blob: Blob): Promise<void> {
    void this.#queue.add(async () => {
      if (!this.#writer || !this.#cameraChannel) {
        return;
      }
      const { id, rootType } = await this.#cameraChannel;
      const now = this.#time();
      const msg: ProtobufObject<CompressedImage> = {
        timestamp: toProtobufTime(fromNanoSec(now)),
        frame_id: "camera",
        data: new Uint8Array(await blob.arrayBuffer()),
        format: blob.type,
      };
      await this.#writer.addMessage({
        sequence: this.#cameraChannelSeq++,
        channelId: id,
        logTime: now,
        publishTime: now,
        data: rootType.encode(msg).finish(),
      });
      this.messageCount++;
      this.#emit();
    });
  }

  async closeAndRestart(): Promise<Blob> {
    return await this.#queue.add(async () => {
      await this.#writer?.end();
      const blob = new Blob(this.#blobParts);
      this.#reinitializeWriter();
      return blob;
    });
  }
}

type State = {
  bytesWritten: bigint;
  messageCount: number;

  latestMessage: MouseEventMessage | ProtobufObject<PoseInFrame> | undefined;

  addMouseEventMessage: (msg: MouseEventMessage) => void;
  addPoseMessage: (msg: ProtobufObject<PoseInFrame>) => void;
  addCameraImage: (blob: Blob) => void;
  closeAndRestart: () => Promise<Blob>;

  addChunkListener: (listener: () => void) => () => void;
};

const useStore = create<State>((set) => {
  const recorder = new Recorder();
  recorder.addListener("update", () => {
    set({
      bytesWritten: recorder.bytesWritten,
      messageCount: recorder.messageCount,
    });
  });

  return {
    bytesWritten: recorder.bytesWritten,
    messageCount: recorder.messageCount,
    latestMessage: undefined,
    addMouseEventMessage(msg: MouseEventMessage) {
      void recorder.addMouseEvent(msg);
      set({ latestMessage: msg });
    },
    addPoseMessage(msg: ProtobufObject<PoseInFrame>) {
      void recorder.addPose(msg);
      set({ latestMessage: msg });
    },
    addCameraImage(blob: Blob) {
      void recorder.addCameraImage(blob);
    },
    async closeAndRestart() {
      return await recorder.closeAndRestart();
    },
    addChunkListener(listener: () => void) {
      recorder.addListener("chunk", listener);
      return () => {
        recorder.removeListener("chunk", listener);
      };
    },
  };
});

function formatBytes(totalBytes: number) {
  const units = ["B", "kiB", "MiB", "GiB", "TiB"];
  let bytes = totalBytes;
  let unit = 0;
  while (unit + 1 < units.length && bytes >= 1024) {
    bytes /= 1024;
    unit++;
  }
  return `${bytes.toFixed(2)} ${units[unit]!}`;
}

const RADIANS_PER_DEGREE = Math.PI / 180;

// Adapted from https://github.com/mrdoob/three.js/blob/master/src/math/Quaternion.js
function deviceOrientationToPose(
  event: DeviceOrientationEvent
): ProtobufObject<PoseInFrame> {
  const alpha = (event.alpha ?? 0) * RADIANS_PER_DEGREE; // z angle
  const beta = (event.beta ?? 0) * RADIANS_PER_DEGREE; // x angle
  const gamma = (event.gamma ?? 0) * RADIANS_PER_DEGREE; // y angle

  const c1 = Math.cos(beta / 2);
  const c2 = Math.cos(gamma / 2);
  const c3 = Math.cos(alpha / 2);

  const s1 = Math.sin(beta / 2);
  const s2 = Math.sin(gamma / 2);
  const s3 = Math.sin(alpha / 2);

  const x = s1 * c2 * c3 - c1 * s2 * s3;
  const y = c1 * s2 * c3 + s1 * c2 * s3;
  const z = c1 * c2 * s3 + s1 * s2 * c3;
  const w = c1 * c2 * c3 - s1 * s2 * s3;

  return {
    timestamp: toProtobufTime(fromMillis(event.timeStamp)),
    frame_id: "device",
    pose: { position: { x: 0, y: 0, z: 0 }, orientation: { x, y, z, w } },
  };
}

const hasMouse = window.matchMedia("(hover: hover)").matches;

export function McapRecordingDemo(): JSX.Element {
  const state = useStore();

  // Automatically start recording if we believe the device has a mouse (which means it is likely
  // not to support orientation events)
  const [recording, setRecording] = useState(hasMouse);
  const [orientationPermissionError, setOrientationPermissionError] =
    useState(false);

  const videoRef = useRef<HTMLVideoElement>(null);
  const [recordingVideo, setRecordingVideo] = useState(false);
  const [videoStarted, setVideoStarted] = useState(false);
  const [videoPermissionError, setVideoPermissionError] = useState(false);

  const chunkIconRef = useRef<HTMLDivElement>(null);
  const fileIconRef = useRef<HTMLDivElement>(null);

  const {
    addCameraImage,
    addMouseEventMessage,
    addPoseMessage,
    addChunkListener,
  } = state;

  const messagesSinceLastChunkRef = useRef(0);
  const animateParticle = useCallback(
    (
      start: { x: number; y: number } | HTMLElement | null,
      endElement?: HTMLElement | null
    ) => {
      if (!start || !endElement) {
        return;
      }
      const endRect = endElement.getBoundingClientRect();

      const particle = document.createElement("div");
      particle.style.width = "5px";
      particle.style.height = "5px";
      particle.style.backgroundColor = "rgba(0, 0, 255, 0.5)";
      particle.style.borderRadius = "50%";
      particle.style.position = "absolute";
      particle.style.top = "0";
      particle.style.left = "0";
      document.body.appendChild(particle);

      let startX, startY;
      if (start instanceof HTMLElement) {
        const startRect = start.getBoundingClientRect();
        startX = startRect.left + Math.random() * startRect.width;
        startY = startRect.top + Math.random() * startRect.height;
      } else {
        startX = start.x;
        startY = start.y;
      }
      const endX =
        endRect.left + (0.5 + 0.2 * (Math.random() - 0.5)) * endRect.width;
      const endY =
        endRect.top + (0.5 + 0.2 * (Math.random() - 0.5)) * endRect.height;
      const animation = particle.animate(
        [
          { transform: `translate(${startX}px, ${startY}px)` },
          { transform: `translate(${endX}px, ${endY}px)` },
        ],
        { duration: 500 }
      );
      animation.onfinish = () => {
        particle.remove();
      };
    },
    []
  );

  useEffect(() => {
    return addChunkListener(() => {
      for (let i = 0; i < messagesSinceLastChunkRef.current; i++) {
        animateParticle(chunkIconRef.current, fileIconRef.current);
      }
      messagesSinceLastChunkRef.current = 0;
    });
  }, [addChunkListener, animateParticle]);

  useEffect(() => {
    if (!recording) {
      return;
    }

    const handleMouseEvent = (event: MouseEvent) => {
      addMouseEventMessage({ clientX: event.clientX, clientY: event.clientY });
      animateParticle(
        { x: event.clientX, y: event.clientY },
        chunkIconRef.current
      );
      messagesSinceLastChunkRef.current++;
    };
    const handleDeviceOrientationEvent = (event: DeviceOrientationEvent) => {
      addPoseMessage(deviceOrientationToPose(event));
    };
    window.addEventListener("pointermove", handleMouseEvent);
    window.addEventListener("deviceorientation", handleDeviceOrientationEvent);
    return () => {
      window.removeEventListener("pointermove", handleMouseEvent);
      window.removeEventListener(
        "deviceorientation",
        handleDeviceOrientationEvent
      );
    };
  }, [addMouseEventMessage, addPoseMessage, animateParticle, recording]);

  useEffect(() => {
    const video = videoRef.current;
    if (!recordingVideo || !video) {
      return;
    }
    const controller = new AbortController();
    void (async (signal: AbortSignal) => {
      let stream: MediaStream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
      } catch (error) {
        setVideoPermissionError(true);
        return;
      }
      if (signal.aborted) {
        return;
      }
      video.srcObject = stream;
      try {
        await video.play();
      } catch (error) {
        // Interrupted: https://developer.chrome.com/blog/play-request-was-interrupted/
        console.error(error);
        return;
      }

      if (!signal.aborted) {
        setVideoStarted(true);
      }

      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");

      let framePromise: Promise<void> | undefined;
      const frameDurationSec = 1 / 30;
      const interval = setInterval(() => {
        if (framePromise) {
          // last frame is not yet complete, skip frame
          return;
        }
        framePromise = new Promise((resolve) => {
          ctx?.drawImage(video, 0, 0);
          canvas.toBlob(
            (blob) => {
              if (blob && !signal.aborted) {
                addCameraImage(blob);
                animateParticle(video, chunkIconRef.current);
                messagesSinceLastChunkRef.current++;
              }
              resolve();
              framePromise = undefined;
            },
            "image/jpeg",
            0.8
          );
        });
      }, frameDurationSec * 1000);

      const cleanup = () => {
        clearInterval(interval);
        for (const track of stream.getTracks()) {
          track.stop();
        }
      };
      if (signal.aborted) {
        cleanup();
      } else {
        signal.addEventListener("abort", cleanup);
      }
    })(controller.signal);

    return () => {
      controller.abort();
    };
  }, [addCameraImage, animateParticle, recordingVideo]);

  const onStartRecording = useCallback(async () => {
    if (
      typeof DeviceOrientationEvent !== "undefined" &&
      "requestPermission" in DeviceOrientationEvent &&
      typeof DeviceOrientationEvent.requestPermission === "function"
    ) {
      const result: unknown = await DeviceOrientationEvent.requestPermission();
      if (result !== "granted") {
        setOrientationPermissionError(true);
      }
    }
    // Even if a permission error was encountered, we can record pointer events
    setRecording(true);
  }, []);

  const onDownloadClick = useCallback(() => {
    void (async () => {
      const blob = await state.closeAndRestart();
      const url = URL.createObjectURL(blob);
      const link = document.createElement("a");
      link.href = url;
      link.download = "demo.mcap";
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      URL.revokeObjectURL(url);
    })();
  }, [state]);

  return (
    <div style={{ display: "flex" }}>
      <div>
        <label>
          Camera
          <input
            type="checkbox"
            checked={recordingVideo}
            disabled={!recording}
            onChange={(event) => {
              setVideoStarted(false);
              setRecordingVideo(event.target.checked);
            }}
          />
        </label>
        {recordingVideo && !videoPermissionError && (
          <div style={{ width: 150, height: 100, position: "relative" }}>
            <video
              ref={videoRef}
              style={{ width: "100%", height: "100%" }}
              muted
              playsInline
            />
            {!videoStarted && (
              <div
                style={{
                  position: "absolute",
                  left: "50%",
                  top: "50%",
                  transform: `translate(-50%,-50%)`,
                }}
              >
                <progress />
              </div>
            )}
          </div>
        )}
        <p>Messages: {state.messageCount}</p>
        {state.latestMessage && "clientX" in state.latestMessage && (
          <>
            <p>
              <strong>Mouse</strong>
            </p>
            <p>clientX: {state.latestMessage.clientX}</p>
            <p>clientY: {state.latestMessage.clientY}</p>
          </>
        )}
        {state.latestMessage && "frame_id" in state.latestMessage && (
          <>
            <p>
              <strong>Pose</strong>
            </p>
            <p>x: {state.latestMessage.pose.orientation.x.toFixed(3)}</p>
            <p>y: {state.latestMessage.pose.orientation.y.toFixed(3)}</p>
            <p>z: {state.latestMessage.pose.orientation.z.toFixed(3)}</p>
            <p>w: {state.latestMessage.pose.orientation.w.toFixed(3)}</p>
          </>
        )}
        {recording ? (
          <button onClick={onDownloadClick}>
            Download ({formatBytes(Number(state.bytesWritten))})
          </button>
        ) : (
          <button
            style={{ backgroundColor: "red" }}
            onClick={() => void onStartRecording()}
          >
            Record
          </button>
        )}
        {orientationPermissionError && (
          <div style={{ color: "red" }}>
            Allow permission to use device orientation
          </div>
        )}
        {videoPermissionError && (
          <div style={{ color: "red" }}>
            Allow permission to record camera images
          </div>
        )}
      </div>
      <div
        ref={chunkIconRef}
        style={{ width: 50, height: 50, margin: 12, border: "1px solid gray" }}
      >
        Chunk
      </div>
      <div
        ref={fileIconRef}
        style={{ width: 50, height: 50, margin: 12, border: "1px solid gray" }}
      >
        File
      </div>
    </div>
  );
}
